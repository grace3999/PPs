{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_FIFI_image_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grace3999/PPs/blob/master/5_FIFI_image_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muw3FEkPP6Px",
        "colab_type": "code",
        "outputId": "dd747a5e-6efd-4416-b8d1-6a4d20a8d7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH7kQz7BQBza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "094a891b-975f-4e2b-8734-fcbb66b7782d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests \n",
        "from multiprocessing.pool import ThreadPool\n",
        "import time\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQELLXJfXFEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "56411a56-c7c5-49bd-aa53-6f0a7f6d1269"
      },
      "source": [
        "#get list of photo urls corresponding to each FIFI category\n",
        "\n",
        "#path for FIFI cleaned and preprocessed data frame\n",
        "path_FIFI = '/content/gdrive/My Drive/WIDS_FIFI_groupproject/generated_datasets/data_final.pkl'\n",
        "\n",
        "#read in pkl file containing \n",
        "data = pd.read_pickle(path_FIFI)\n",
        "data = pd.DataFrame(data = data)\n",
        "data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "print('Original data shape:\\n', data.shape, '\\n')\n",
        "print('Original data columns:\\n', data.columns.values, '\\n')\n",
        "\n",
        "data = data[data['FIFI_category'] != 'Community Walk']\n",
        "\n",
        "data['FIFI_category'] = data['FIFI_category'].replace({'Needles/Dumping': 'Needles_Dumping', 'Sign/Signal': 'Sign_Signal'})\n",
        "\n",
        "#we are only interested in FIFI requests that have a photo included with the request\n",
        "print(data.shape)\n",
        "data_photo = data[~data['Photo'].isna()]\n",
        "print(data_photo.shape)\n",
        "\n",
        "#create a directory for each category\n",
        "os.mkdir('/tmp/FIFI_photos/')\n",
        "save_path = '/tmp/FIFI_photos/'\n",
        "\n",
        "cats_to_dl = ['Abnd_Vehicle', 'Grafitti', 'Needles_Dumping', 'Parking',\n",
        "       'Pothole', 'Streetlight', 'Other', 'Clogged_Drain', 'Dead Animal',\n",
        "       'Vegetation', 'Sign_Signal']\n",
        "\n",
        "#get and save photos according to FIFI_category\n",
        "for cat in cats_to_dl:\n",
        "    if os.path.exists(os.path.join(save_path, cat)) == True:\n",
        "      print(cat, \" already exists\")\n",
        "    else:\n",
        "      os.mkdir(os.path.join(save_path, cat))\n",
        "      print(cat, \" directory created\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original data shape:\n",
            " (248815, 67) \n",
            "\n",
            "Original data columns:\n",
            " ['Service_Request_Number' 'Created_Date' 'Location' 'Location_Details'\n",
            " 'Description' 'License_Number' 'State' 'Vehicle_Make' 'Vehicle_Color'\n",
            " 'Time_parked' 'Photo' 'FIFI_category' 'Location_Details.1'\n",
            " 'Property_damage?' 'Current_Issue' 'Type_of_animal'\n",
            " 'On_private_property?' 'Graffiti_location' 'Location_and_Description'\n",
            " 'Obscene/Racial/Hateful?' 'Street/Intersection' 'Where?' 'Type_of_item?'\n",
            " 'Veg_location' 'Vegetation_Safety_Issue' 'Parking_Violation_Concerning'\n",
            " 'License_Plate_Number' 'Location_details' '7_digit_number_on_pole'\n",
            " 'Issue' 'date' 'year' 'month' 'day' 'day_of_week' 'hour' 'zip'\n",
            " 'neighborhood' 'SittingInformal' 'Lying' 'DisruptiveActivity_Aggressive'\n",
            " 'DisruptiveActivity_Intoxicated' 'LivingActivities' 'Soliciting'\n",
            " 'overdose' 'pop' 'pop_dens' 'housing_units' 'med_home' 'land_area'\n",
            " 'occupied_units' 'occupied_ratio' 'med_income' 'med_age' 'male_%'\n",
            " 'white_%' 'fam_%' 'nokid_%' 'mortgage_%' 'fulltime_%' 'unemploy'\n",
            " 'drive_%' 'publictrans_%' 'other_%' 'wrk_travel' 'city council'\n",
            " 'county council'] \n",
            "\n",
            "(248661, 67)\n",
            "(183278, 67)\n",
            "Abnd_Vehicle  directory created\n",
            "Grafitti  directory created\n",
            "Needles_Dumping  directory created\n",
            "Parking  directory created\n",
            "Pothole  directory created\n",
            "Streetlight  directory created\n",
            "Other  directory created\n",
            "Clogged_Drain  directory created\n",
            "Dead Animal  directory created\n",
            "Vegetation  directory created\n",
            "Sign_Signal  directory created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez8rNpjfXX3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccf1ed42-c27f-41f4-92db-c51d250edb1a"
      },
      "source": [
        "#create function to get photo from url and save\n",
        "\n",
        "def fetch_and_save(image_url_tupple):\n",
        "    image_name, image_url = image_url_tupple\n",
        "    #create file name for photo\n",
        "    image_name = os.path.join(save_path_cat, image_name)  \n",
        "    #get photo from url and save\n",
        "    r = requests.get(image_url, allow_redirects=True)\n",
        "    open(image_name, 'wb').write(r.content)\n",
        "\n",
        "#do each category individually and 5,000 at a time (runtime keeps dying)\n",
        "save_path = '/tmp/FIFI_photos/'\n",
        "\n",
        "cats_to_dl = ['Abnd_Vehicle', 'Grafitti', 'Needles_Dumping', 'Parking',\n",
        "       'Pothole', 'Streetlight', 'Other', 'Clogged_Drain', 'Dead Animal',\n",
        "       'Vegetation', 'Sign_Signal']\n",
        "\n",
        "cat = cats_to_dl[0]\n",
        "print(cat)\n",
        "cat_data = data_photo[data_photo['FIFI_category'] == cat].reset_index() #index will get saved as part of file name for later use\n",
        "\n",
        "save_path_cat = os.path.join(save_path, cat)\n",
        "\n",
        "i = 0\n",
        "while i < (5000):\n",
        "  if i%50 == 0:\n",
        "    print(i)\n",
        "  urls = list(zip([cat+'_'+str(x)+'.jpeg' for x in cat_data.index.values[i:i+5]], cat_data['Photo'][i:i+5]))\n",
        "  ThreadPool(5).imap_unordered(fetch_and_save, urls)\n",
        "  i += 5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abnd_Vehicle\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-JwdeMcJJS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create directories for training and testing \n",
        "project_dir = '/tmp/'\n",
        "\n",
        "try:\n",
        "  os.mkdir(os.path.join(project_dir, 'cnn_cat_other'))\n",
        "except OSError:\n",
        "  pass\n",
        "try:\n",
        "  os.mkdir(os.path.join(project_dir, 'cnn_cat_other/training'))\n",
        "except OSError:\n",
        "  pass\n",
        "try:\n",
        "  os.mkdir(os.path.join(project_dir, 'cnn_cat_other/testing'))\n",
        "except OSError:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL2c2MQ8MUlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create directories for train/test for each FIFI category \n",
        "photo_categories = ['Needles_Dumping', 'Grafitti', 'Abnd_Vehicle', 'Parking', 'Pothole', 'Sign_Signal', 'Streetlight']\n",
        "\n",
        "train_dir = '/tmp/cnn_cat_other/training/'\n",
        "test_dir = '/tmp/cnn_cat_other/testing/'\n",
        "\n",
        "for cat in photo_categories:\n",
        "  try:\n",
        "    os.mkdir(os.path.join(train_dir, cat))\n",
        "  except OSError:\n",
        "   print('cannot make directory for train: ', cat)\n",
        "  try:\n",
        "    os.mkdir(os.path.join(test_dir, cat))\n",
        "  except OSError:\n",
        "   print('cannot make directory for test: ', cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YdQqpaAJGiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to split data into training and testing based on a specified split size\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = os.path.join(SOURCE, filename)\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = os.path.join(SOURCE, filename)\n",
        "        destination = os.path.join(TRAINING, filename)\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = os.path.join(SOURCE, filename)\n",
        "        destination = os.path.join(TESTING, filename)\n",
        "        copyfile(this_file, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll7zsSIfN1tF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c1764b7-965d-45b3-d388-5f5e3d1cae96"
      },
      "source": [
        "photos_dir = '/tmp/FIFI_photos/'\n",
        "train_dir = '/tmp/cnn_cat_other/training/'\n",
        "test_dir = '/tmp/cnn_cat_other/testing/'\n",
        "\n",
        "for cat in photo_categories[2:3]:\n",
        "  source_dir = os.path.join(photos_dir, cat)\n",
        "  train_dir = os.path.join(train_dir, cat)\n",
        "  test_dir = os.path.join(test_dir, cat)\n",
        "\n",
        "  split_size = .9\n",
        "  start_time = time.time()\n",
        "  split_data(source_dir, train_dir, test_dir, split_size)\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 4.332841634750366 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeHsxY2nyZEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGGf-qpAyZHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL4wQ9ktyZKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKEMBfpGyZNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}