{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing OCR and preparation of City of Seattle homeless encampment sweep pdf data for use with data viz and NLP of Find it Fix It requests to the City of Seattle (from a FOI request)\n",
    "\n",
    "PDFs downloaded from: https://www.seattle.gov/homelessness/unauthorized-encampments/encampment-removals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys \n",
    "import datetime as dt\n",
    "import string\n",
    "#OCR related\n",
    "from PIL import Image \n",
    "import pytesseract \n",
    "from pdf2image import convert_from_path \n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('poster', rc={'font.size':35,\n",
    "                              'axes.titlesize':50,\n",
    "                              'axes.labelsize':35})\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General plan:\n",
    "\n",
    "1. convert each pdf to a jpeg (using pdf2image convert_from_path)\n",
    "2. convert text in each jpeg to text (using pytesseract and PIL)\n",
    "\n",
    "3. save the following info from the extracted text:\n",
    "    * site_address\n",
    "    * date_insp\n",
    "    * date_cleanup\n",
    "    * referred_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths \n",
    "pdf_path = 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_PDFs'\n",
    "jpeg_path = 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list pdfs in path\n",
    "pdfs_in_path = os.listdir(pdf_path)\n",
    "print(len(pdfs_in_path), '\\n', pdfs_in_path[0])\n",
    "\n",
    "#create path names for pdfs in path\n",
    "pdf_path_names = []\n",
    "for pdf in pdfs_in_path:\n",
    "    path_name = pdf_path + '/' + pdf\n",
    "    pdf_path_names.append(path_name)\n",
    "\n",
    "print(len(pdf_path_names))\n",
    "pdf_path_names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pdf to jpeg images\n",
    "#right now we only care about data contained on the fist page of the pdf\n",
    "\n",
    "for pdf in pdf_path_names:\n",
    "    try:\n",
    "        convert_from_path(pdf, \n",
    "                      dpi=200, \n",
    "                      output_file=pdf,\n",
    "                      output_folder=jpeg_path, \n",
    "                      first_page=1, last_page=1, \n",
    "                      fmt='jpeg')\n",
    "    except:\n",
    "        print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 \n",
      " 01-30-19 6th Ave and Yesler.pdf0001-01.jpg\n",
      "103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/01-30-19 6th Ave and Yesler.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/02-26-19 SW Florida St from 13th Ave SW to 11th Ave SW.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/03.05.2019-Aurora-Ave-N-N-128th-St.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/03.12.2019-8th-Ave-S-S-Holgate-St.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/03.18-21.2019 Fremont Troll Area.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/05-28-19 Klictitat Ave SW under the SW Spokane St and West Seattle Bridge.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/06-21-19 Corson Ave S and S Carstens Pl OBSTRUCTION.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/06-29-19 Hillside West of Sound Transit  Yard at S Dearborn St and 12th.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/07-19-19 S Industrial Way btwn Airport Way St and 4th Ave S.pdf0001-01.jpg',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/08-01-19 E Marginal Way Atlantic to Terminal 30 along BNSF Rail.pdf0001-01.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list jpegs in path\n",
    "jpegs_in_path = os.listdir(jpeg_path)\n",
    "print(len(jpegs_in_path), '\\n', jpegs_in_path[0])\n",
    "\n",
    "#create path names for jpegs in path, jpegs have more than one page, save each page separately\n",
    "jpeg_path_names = []\n",
    "for jpeg in jpegs_in_path:\n",
    "    path_name = jpeg_path + '/' + jpeg\n",
    "    jpeg_path_names.append(path_name)\n",
    "\n",
    "print(len(jpeg_path_names))\n",
    "jpeg_path_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_from_jpeg(path_name):\n",
    "    ### takes in path of image, performs OCR, saves split text ###\n",
    "    \n",
    "    #OCR with pytesseract\n",
    "    text = str(((pytesseract.image_to_string(Image.open(path_name))))) \n",
    "    text_split = text.split(\"\\n\")\n",
    "    \n",
    "    return text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_from_OCR(text_split, site_words, name):\n",
    "    ### takes in path of image, performs OCR, saves specific info as dic ###\n",
    "    \n",
    "    sweep_OCR_dic = {}\n",
    "    sweep_OCR_dic['name'] = name.split(\"/\")[-1]\n",
    "    \n",
    "    #OCR with pytesseract\n",
    "    text = str(((pytesseract.image_to_string(Image.open(path_name))))) \n",
    "    text_split = text.split(\"\\n\")\n",
    "    \n",
    "    #date of inspection\n",
    "    for key_word in site_words:\n",
    "        try:\n",
    "            site_insp = [s for s in text_split if key_word in s]\n",
    "            sweep_OCR_dic['date_insp'] = re.findall(r\"Inspection:.*\", site_insp[0])[0].split(\" \")[-1]\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    #address of site clean up\n",
    "    for key_word in address_words:\n",
    "        try:\n",
    "            add_cleanup = [s for s in text_split if key_word in s]\n",
    "            sweep_OCR_dic['site_address'] = re.findall(r\"Address: (.*) Date\", add_cleanup[0])[0]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #date of clean up\n",
    "    try:\n",
    "        sweep_OCR_dic['date_cleanup'] = re.findall(r\"(Clean-Up: |Date of clean: |Date of Clean-Up: )(.*)\", add_cleanup[0])[0][-1]\n",
    "    except:\n",
    "        date_cleanup = [s for s in text_split if 'Date of Clean-Up: ' in s]\n",
    "        sweep_OCR_dic['date_cleanup'] = re.findall(r\"(Clean-Up: |Date of clean: |Date of Clean-Up: )(.*)\", date_cleanup[0])[0][-1]\n",
    "        \n",
    "    #who referred the site for clean up\n",
    "    ref = [s for s in text_split if \"Referred By:\" in s]\n",
    "    sweep_OCR_dic['ref_by'] = re.findall(r\"Referred By: (.*) (Photos|CSR|SPD)\", ref[0])[0]\n",
    "\n",
    "    return sweep_OCR_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/1.8.19-1st-Ave-S-and-Denver-Ave-S.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/10-24-2018-WSBridge-Harbor-Ave-Spokane-St.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/11.01.18-Yesler-Way-6th-Ave-I-5-under-Yesler-Way-overpass.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "41\n",
      "42\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/11.07.18-Airport-Way-S-from-S-Massachu.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "43\n",
      "44\n",
      "45\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/11.14.18-Georgetown-Pump-Station-along-8th-Ave-S-to-Myrtle-St.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "46\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/11.20.18-1st-Ave-S-and-S-Front-St.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "47\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/11.21.18-Shilshole-Ave-NW-from-14th-to-17th-Ave-NW.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/4.11.2019-Leary-Triangle-8th-Ave-NW-NW-43rd.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/5.22.2019-Dearborn-Corridor-Obstruction-Under-I-5-at-Dearborn-St-to-EB-and-NB-off-Ramps.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "C:/Users/Schindler/Documents/ProgrammingFun/FIFI/OCR/sweep_JPEGs/9-13-18-Fremont-Canal.pdf0001-01.jpg\n",
      "cannot get info from text_split\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "(93, 5)\n",
      "10 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_cleanup</th>\n",
       "      <th>date_insp</th>\n",
       "      <th>name</th>\n",
       "      <th>ref_by</th>\n",
       "      <th>site_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/30/2019</td>\n",
       "      <td>01-14-19</td>\n",
       "      <td>01-30-19 6th Ave and Yesler.pdf0001-01.jpg</td>\n",
       "      <td>(SERIS, Community, Photos)</td>\n",
       "      <td>6\" Ave and Yesler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/26/19</td>\n",
       "      <td>2/20/19</td>\n",
       "      <td>02-26-19 SW Florida St from 13th Ave SW to 11th Ave SW.pdf0001-01.jpg</td>\n",
       "      <td>(SPU, Photos)</td>\n",
       "      <td>SW Florida St from 13th Ave SW to 11th Ave SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-05-19</td>\n",
       "      <td>01-14-19</td>\n",
       "      <td>03.05.2019-Aurora-Ave-N-N-128th-St.pdf0001-01.jpg</td>\n",
       "      <td>(SPU, Photos)</td>\n",
       "      <td>Stone Ave N to Aurora Ave N from N 125th St to N 130th St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/12/19</td>\n",
       "      <td>2/7/19</td>\n",
       "      <td>03.12.2019-8th-Ave-S-S-Holgate-St.pdf0001-01.jpg</td>\n",
       "      <td>(SPU, Photos)</td>\n",
       "      <td>I-5 SB to the SODO Trail from S Massachusetts St toS Walker St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/18-21/19</td>\n",
       "      <td>11/30/18</td>\n",
       "      <td>03.18-21.2019 Fremont Troll Area.pdf0001-01.jpg</td>\n",
       "      <td>(CSR, Community, Photos)</td>\n",
       "      <td>N 36\" St to N 38* St from Linden Ave N to Winslow PLN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_cleanup date_insp                                                                   name                      ref_by                                                    site_address\n",
       "0  01/30/2019   01-14-19  01-30-19 6th Ave and Yesler.pdf0001-01.jpg                             (SERIS, Community, Photos)  6\" Ave and Yesler                                             \n",
       "0  2/26/19      2/20/19   02-26-19 SW Florida St from 13th Ave SW to 11th Ave SW.pdf0001-01.jpg  (SPU, Photos)               SW Florida St from 13th Ave SW to 11th Ave SW                 \n",
       "0  03-05-19     01-14-19  03.05.2019-Aurora-Ave-N-N-128th-St.pdf0001-01.jpg                      (SPU, Photos)               Stone Ave N to Aurora Ave N from N 125th St to N 130th St     \n",
       "0  3/12/19      2/7/19    03.12.2019-8th-Ave-S-S-Holgate-St.pdf0001-01.jpg                       (SPU, Photos)               I-5 SB to the SODO Trail from S Massachusetts St toS Walker St\n",
       "0  3/18-21/19   11/30/18  03.18-21.2019 Fremont Troll Area.pdf0001-01.jpg                        (CSR, Community, Photos)    N 36\" St to N 38* St from Linden Ave N to Winslow PLN         "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_info_df = pd.DataFrame()\n",
    "except_paths = []\n",
    "i=0\n",
    "site_words = ['Site:', 'CSR Listing:', 'CRS Listing:', 'CSR Address:']\n",
    "address_words = ['CSR Address:', 'Site Address:']\n",
    "\n",
    "for path_name in jpeg_path_names:\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    #OCR\n",
    "    try:\n",
    "        text_split = OCR_from_jpeg(path_name)\n",
    "    except:\n",
    "        print(path_name)\n",
    "        print('cannot perform OCR')\n",
    "    \n",
    "    #get desired sweep metadata\n",
    "    try:\n",
    "        dic = info_from_OCR(text_split, site_words, name=path_name)\n",
    "        df = pd.DataFrame.from_dict(dic, orient='index').T\n",
    "    \n",
    "        if sweep_info_df.shape[0] == 0:\n",
    "            sweep_info_df = df\n",
    "        else:\n",
    "            sweep_info_df = sweep_info_df.append(df)\n",
    "\n",
    "    except:\n",
    "        print(path_name)\n",
    "        print('cannot get info from text_split')\n",
    "        except_paths.append(path_name)\n",
    "        \n",
    "    i+=1\n",
    "\n",
    "print(sweep_info_df.shape)\n",
    "print(len(except_paths), '\\n')\n",
    "sweep_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_cleanup</th>\n",
       "      <th>date_insp</th>\n",
       "      <th>name</th>\n",
       "      <th>ref_by</th>\n",
       "      <th>site_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>01-14-19</td>\n",
       "      <td>01-30-19 6th Ave and Yesler.pdf0001-01.jpg</td>\n",
       "      <td>SERIS, Community</td>\n",
       "      <td>6\" Ave and Yesler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2-20-19</td>\n",
       "      <td>02-26-19 SW Florida St from 13th Ave SW to 11th Ave SW.pdf0001-01.jpg</td>\n",
       "      <td>SPU</td>\n",
       "      <td>SW Florida St from 13th Ave SW to 11th Ave SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>01-14-19</td>\n",
       "      <td>03.05.2019-Aurora-Ave-N-N-128th-St.pdf0001-01.jpg</td>\n",
       "      <td>SPU</td>\n",
       "      <td>Stone Ave N to Aurora Ave N from N 125th St to N 130th St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>2-7-19</td>\n",
       "      <td>03.12.2019-8th-Ave-S-S-Holgate-St.pdf0001-01.jpg</td>\n",
       "      <td>SPU</td>\n",
       "      <td>I-5 SB to the SODO Trail from S Massachusetts St toS Walker St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>11-30-18</td>\n",
       "      <td>03.18-21.2019 Fremont Troll Area.pdf0001-01.jpg</td>\n",
       "      <td>CSR, Community</td>\n",
       "      <td>N 36\" St to N 38* St from Linden Ave N to Winslow PLN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_cleanup date_insp                                                                   name            ref_by                                                    site_address\n",
       "0 2019-01-30    01-14-19  01-30-19 6th Ave and Yesler.pdf0001-01.jpg                             SERIS, Community  6\" Ave and Yesler                                             \n",
       "1 2019-02-26    2-20-19   02-26-19 SW Florida St from 13th Ave SW to 11th Ave SW.pdf0001-01.jpg  SPU               SW Florida St from 13th Ave SW to 11th Ave SW                 \n",
       "2 2019-03-05    01-14-19  03.05.2019-Aurora-Ave-N-N-128th-St.pdf0001-01.jpg                      SPU               Stone Ave N to Aurora Ave N from N 125th St to N 130th St     \n",
       "3 2019-03-12    2-7-19    03.12.2019-8th-Ave-S-S-Holgate-St.pdf0001-01.jpg                       SPU               I-5 SB to the SODO Trail from S Massachusetts St toS Walker St\n",
       "4 2019-03-18    11-30-18  03.18-21.2019 Fremont Troll Area.pdf0001-01.jpg                        CSR, Community    N 36\" St to N 38* St from Linden Ave N to Winslow PLN         "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up data frame\n",
    "sweep_info_df_final = sweep_info_df.reset_index(drop=True)\n",
    "sweep_info_df_final.replace(np.nan, 'empty', inplace=True)\n",
    "#remove 'photos' from ref column\n",
    "sweep_info_df_final['ref_by'] = sweep_info_df_final['ref_by'].apply(lambda x: x[0] if x[-1] == 'Photos' else x)\n",
    "\n",
    "#fix dates - multiple formats and some with a date span\n",
    "sweep_info_df_final['date_insp'] = sweep_info_df_final['date_insp'].apply(lambda x: re.split('/|-', x))\n",
    "sweep_info_df_final['date_insp'] = sweep_info_df_final['date_insp'].apply(lambda x: x[0]+'-'+x[1]+'-'+x[-1] if len(x) > 1 else np.nan)\n",
    "sweep_info_df_final['date_insp'] = pd.to_datetime(sweep_info_df_final['date_insp'], infer_datetime_format=True, errors='ignore')\n",
    "\n",
    "sweep_info_df_final['date_cleanup'] = sweep_info_df_final['date_cleanup'].apply(lambda x: re.split('/|-', x))\n",
    "sweep_info_df_final['date_cleanup'] = sweep_info_df_final['date_cleanup'].apply(lambda x: x[0]+'-'+x[1]+'-'+x[-1] if len(x) > 1 else np.nan)\n",
    "sweep_info_df_final['date_cleanup'] = pd.to_datetime(sweep_info_df_final['date_cleanup'], infer_datetime_format=True, errors='ignore')\n",
    "\n",
    "sweep_info_df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_info_df_final.to_csv('sweep_info_df_final.csv')\n",
    "except_paths = pd.DataFrame(data=except_paths)\n",
    "except_paths.to_csv('except_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSR, Community                   18\n",
       "SPU                              8 \n",
       "SERIS, Community                 8 \n",
       "Community, CSR                   8 \n",
       "SPU, Community, CSR              5 \n",
       "SPU, SERIS, Community            4 \n",
       "(Community,, CSR)                4 \n",
       "SPU, CSR, Community              4 \n",
       "(SPU,, CSR)                      3 \n",
       "SPU, Community                   3 \n",
       "WSDOT, SERIS, Community          2 \n",
       "WSDOT, CSR, Community            2 \n",
       "(WSDOT, Community,, CSR)         2 \n",
       "WSDOT, Community, CSR            2 \n",
       "Sound Transit, Community, CSR    2 \n",
       "WSDOT                            2 \n",
       "SPD, CSR, Community              2 \n",
       "CSR, SPU, Community              1 \n",
       "(SERIS, CRS, Community,, SPD)    1 \n",
       "BNSF, Community, CSR             1 \n",
       "SPU, CSR                         1 \n",
       "CSR, WSDOT, Community            1 \n",
       "SDOT, Sound Transit              1 \n",
       "CSR, EPA, SPU                    1 \n",
       "© CSR, Community                 1 \n",
       "(WDSOT, Community,, CSR)         1 \n",
       "Community/CSR                    1 \n",
       "Citizen, SERIS                   1 \n",
       "Parks, SDOT, SERIS, Community    1 \n",
       "Sound Transit , Community        1 \n",
       "(SPD,, CSR)                      1 \n",
       "Name: ref_by, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_info_df_final['ref_by'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
